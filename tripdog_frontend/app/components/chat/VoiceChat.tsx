"use client"

import React, {useState, useCallback, useRef, useEffect} from 'react';
import {
    useSpeechRecognition,
    useOpenAITTS,
    AudioPlayer,
    AudioVisualizer,
    useAudioPlayer,
    useEdgeSpeech
} from '@lobehub/tts/react';
import {Icon} from '@lobehub/ui';
import {Button, Input, Card, Space, message, Spin} from 'antd';
import {Mic, StopCircle, Volume2, Send, Bot, User} from 'lucide-react';
import {Flexbox} from 'react-layout-kit';

// é…ç½®æ¥å£
interface VoiceAssistantConfig {
    OPENAI_API_KEY: string;
    OPENAI_PROXY_URL?: string;
    serviceUrl?: string;
}

// æ¶ˆæ¯ç±»å‹
interface Message {
    id: string;
    role: 'user' | 'assistant';
    content: string;
    timestamp: Date;
}

const VoiceAssistant: React.FC<{ config: VoiceAssistantConfig }> = ({config}) => {
    // çŠ¶æ€ç®¡ç†
    const [messages, setMessages] = useState<Message[]>([]);
    const [currentInput, setCurrentInput] = useState('');
    const [isProcessingAI, setIsProcessingAI] = useState(false);
    const [autoPlayResponse, setAutoPlayResponse] = useState(true);
    const audioRef = useRef<HTMLAudioElement>(null!);

    // è¯­éŸ³è¯†åˆ« (STT)
    const {
        text: recognizedText,
        start: startRecording,
        stop: stopRecording,
        isLoading: isRecognizing,
        isRecording,
        formattedTime,
    } = useSpeechRecognition('zh-CN', {
        autoStop: true,
        onRecognitionFinish: async (text: string) => {
            if (text) {
                setCurrentInput(text);
                // è‡ªåŠ¨å‘é€è¯†åˆ«çš„æ–‡æœ¬
                await handleSendMessage(text);
            }
        },
        onRecognitionError: async (error: Error) => {
            message.error(`è¯­éŸ³è¯†åˆ«å¤±è´¥: ${error.message}`);
        },
    });

    // æ–‡å­—è½¬è¯­éŸ³ (TTS)
    const {
        setText: setTTSText,
        isGlobalLoading: isTTSLoading,
        audio: ttsAudio,
        start: startTTS,
        stop: stopTTS
    } = useEdgeSpeech('', {
        api: config,
        options: {
            voice: 'zh-CN-YunxiaNeural', // å¯ä»¥æ”¹ä¸ºå…¶ä»–å£°éŸ³: nova, shimmer, echo, fable, onyx
            //model: 'tts-1',
        },
    });

    // è°ƒç”¨AIè·å–å›ç­”
    const getAIResponse = useCallback(async (userMessage: string): Promise<string> => {
        try {
            const response = await fetch(`${config.OPENAI_PROXY_URL || 'https://api.openai.com/v1'}/chat/completions`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${config.OPENAI_API_KEY}`,
                },
                body: JSON.stringify({
                    model: 'gpt-4o-mini',
                    messages: [
                        {role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ï¼Œè¯·ç”¨ç®€æ´æ¸…æ™°çš„è¯­è¨€å›ç­”é—®é¢˜ã€‚'},
                        ...messages.map(msg => ({role: msg.role, content: msg.content})),
                        {role: 'user', content: userMessage}
                    ],
                    max_tokens: 150,
                    temperature: 0.7,
                }),
            });

            if (!response.ok) {
                throw new Error(`APIè¯·æ±‚å¤±è´¥: ${response.status}`);
            }

            const data = await response.json();
            return data.choices[0]?.message?.content || 'æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆå›å¤ã€‚';
        } catch (error) {
            console.error('AIå›ç­”é”™è¯¯:', error);
            return 'æŠ±æ­‰ï¼Œè·å–AIå›å¤æ—¶å‡ºç°é”™è¯¯ï¼Œè¯·æ£€æŸ¥APIé…ç½®ã€‚';
        }
    }, [config, messages]);

    // æ›´æ–° handleSendMessage çš„ useCallback ä¾èµ–æ•°ç»„
    const handleSendMessage = useCallback(async (text?: string) => {
        const messageText = text || currentInput;
        if (!messageText.trim()) return;

        const userMessage: Message = {
            id: `user-${Date.now()}`,
            role: 'user',
            content: messageText,
            timestamp: new Date(),
        };
        setMessages(prev => [...prev, userMessage]);
        setCurrentInput('');
        setIsProcessingAI(true);

        try {
            const aiResponse = await getAIResponse(messageText);

            const assistantMessage: Message = {
                id: `assistant-${Date.now()}`,
                role: 'assistant',
                content: aiResponse,
                timestamp: new Date(),
            };
            setMessages(prev => [...prev, assistantMessage]);

            if (autoPlayResponse) {
                setTTSText(aiResponse);
                setTimeout(() => {
                    startTTS();
                }, 500);
            }
        } catch {
            message.error('å¤„ç†æ¶ˆæ¯æ—¶å‡ºç°é”™è¯¯');
        } finally {
            setIsProcessingAI(false);
        }
    }, [currentInput, autoPlayResponse, setTTSText, startTTS, getAIResponse]);

    // æ‰‹åŠ¨æ’­æ”¾æ¶ˆæ¯è¯­éŸ³
    const playMessageAudio = (content: string) => {
        setTTSText(content);
        setTimeout(() => {
            startTTS();
        }, 100);
    };

    return (
        <Flexbox gap={16} style={{maxWidth: 800, margin: '0 auto', padding: 20}}>
            {/* æ ‡é¢˜æ  */}
            <Card>
                <Flexbox horizontal justify="space-between" align="center">
                    <h2 style={{margin: 0}}>ğŸ™ï¸ AIè¯­éŸ³åŠ©æ‰‹</h2>
                    <Space>
                        <Button
                            size="small"
                            type={autoPlayResponse ? 'primary' : 'default'}
                            onClick={() => setAutoPlayResponse(!autoPlayResponse)}
                        >
                            {autoPlayResponse ? 'è‡ªåŠ¨æ’­æ”¾å›å¤' : 'æ‰‹åŠ¨æ’­æ”¾'}
                        </Button>
                    </Space>
                </Flexbox>
            </Card>

            {/* å¯¹è¯å†å² */}
            <Card style={{minHeight: 400, maxHeight: 500, overflowY: 'auto'}}>
                <Flexbox gap={12}>
                    {messages.length === 0 ? (
                        <div style={{textAlign: 'center', color: '#999', padding: 40}}>
                            ç‚¹å‡»éº¦å…‹é£å¼€å§‹è¯­éŸ³å¯¹è¯ï¼Œæˆ–ç›´æ¥è¾“å…¥æ–‡å­—
                        </div>
                    ) : (
                        messages.map((msg) => (
                            <Flexbox
                                key={msg.id}
                                horizontal
                                gap={8}
                                align="flex-start"
                                style={{
                                    justifyContent: msg.role === 'user' ? 'flex-end' : 'flex-start',
                                }}
                            >
                                {msg.role === 'assistant' && (
                                    <Icon icon={Bot} style={{color: '#1890ff', marginTop: 4}}/>
                                )}
                                <Card
                                    size="small"
                                    style={{
                                        maxWidth: '70%',
                                        backgroundColor: msg.role === 'user' ? '#e6f7ff' : '#f6f6f6',
                                    }}
                                    onClick={() => msg.role === 'assistant' && playMessageAudio(msg.content)}
                                    hoverable={msg.role === 'assistant'}
                                >
                                    <div>{msg.content}</div>
                                    {msg.role === 'assistant' && (
                                        <Button
                                            size="small"
                                            type="text"
                                            icon={<Icon icon={Volume2}/>}
                                            style={{marginTop: 8}}
                                        >
                                            æ’­æ”¾
                                        </Button>
                                    )}
                                </Card>
                                {msg.role === 'user' && (
                                    <Icon icon={User} style={{color: '#52c41a', marginTop: 4}}/>
                                )}
                            </Flexbox>
                        ))
                    )}
                    {isProcessingAI && (
                        <Flexbox horizontal gap={8} align="center">
                            <Icon icon={Bot} style={{color: '#1890ff'}}/>
                            <Card size="small" style={{backgroundColor: '#f6f6f6'}}>
                                <Spin size="small"/> AIæ­£åœ¨æ€è€ƒ...
                            </Card>
                        </Flexbox>
                    )}
                </Flexbox>
            </Card>

            {/* è¾“å…¥åŒºåŸŸ */}
            <Card>
                <Flexbox gap={12}>
                    {/* æ–‡æœ¬è¾“å…¥æ¡† */}
                    <Input.TextArea
                        placeholder="è¾“å…¥æ¶ˆæ¯æˆ–ä½¿ç”¨è¯­éŸ³è¯†åˆ«..."
                        value={currentInput || recognizedText}
                        onChange={(e) => setCurrentInput(e.target.value)}
                        onPressEnter={async (e) => {
                            if (!e.shiftKey) {
                                e.preventDefault();
                                await handleSendMessage();
                            }
                        }}
                        rows={3}
                        disabled={isRecording || isRecognizing}
                    />

                    {/* æ§åˆ¶æŒ‰é’® */}
                    <Flexbox horizontal gap={8}>
                        {/* è¯­éŸ³è¯†åˆ«æŒ‰é’® */}
                        {isRecording ? (
                            <Button
                                danger
                                icon={<Icon icon={StopCircle}/>}
                                onClick={stopRecording}
                                style={{flex: 1}}
                            >
                                åœæ­¢å½•éŸ³ {formattedTime}
                            </Button>
                        ) : isRecognizing ? (
                            <Button loading style={{flex: 1}}>
                                è¯†åˆ«ä¸­...
                            </Button>
                        ) : (
                            <Button
                                type="primary"
                                icon={<Icon icon={Mic}/>}
                                onClick={startRecording}
                                style={{flex: 1}}
                                disabled={isProcessingAI}
                            >
                                å¼€å§‹å½•éŸ³
                            </Button>
                        )}

                        {/* å‘é€æŒ‰é’® */}
                        <Button
                            type="primary"
                            icon={<Icon icon={Send}/>}
                            onClick={() => handleSendMessage()}
                            disabled={!currentInput.trim() || isProcessingAI}
                            loading={isProcessingAI}
                        >
                            å‘é€
                        </Button>
                    </Flexbox>

                    {/* éŸ³é¢‘æ’­æ”¾å™¨å’Œå¯è§†åŒ– */}
                    {ttsAudio && (
                        <Flexbox gap={8}>
                            <Flexbox gap={8}>
                                <AudioPlayer
                                    audio={ttsAudio}
                                    isLoading={isTTSLoading}
                                    onLoadingStop={stopTTS}
                                    style={{ width: '100%' }}
                                />
                                <AudioVisualizer
                                    audioRef={audioRef}
                                    isLoading={isTTSLoading}
                                    barStyle={{
                                        count: 20,
                                        width: 4,
                                        gap: 2,
                                        minHeight: 20,
                                        maxHeight: 60,
                                        borderRadius: 2,
                                    }}
                                />
                            </Flexbox>
                        </Flexbox>
                    )}
                </Flexbox>
            </Card>
        </Flexbox>
    );
};

// ä½¿ç”¨ç¤ºä¾‹
export default function VoiceChat() {
    const config: VoiceAssistantConfig = {
        OPENAI_API_KEY: process.env.NEXT_PUBLIC_OPENAI_API_KEY || '',
        OPENAI_PROXY_URL: process.env.NEXT_PUBLIC_OPENAI_PROXY_URL || 'https://api.openai.com',
    };

    if (!config.OPENAI_API_KEY) {
        return (
            <Card style={{maxWidth: 600, margin: '50px auto'}}>
                <h3>é…ç½®ç¼ºå¤±</h3>
                <p>è¯·åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½® REACT_APP_OPENAI_API_KEY</p>
            </Card>
        );
    }

    return <VoiceAssistant config={config}/>;
}